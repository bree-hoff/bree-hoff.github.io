# Chapters 2: Production
### Setting Up
The set-up of the Google Colab Jupyter Notebook from [the fastai website](https://course.fast.ai/Resources/book.html) was quite straight forward,
though signing up for the Microsoft Azure account was a bit of a pain. From first impressions, the notebook is well formatted and laid-out,
easy to follow and very interactive. However, perhaps it is just a drawback of Google Collab, but the fastbook.setup_book() function often takes many minutes, and is repeated in each chapter of the notebook.  
### Background on Deep Learning
Chapter 2 begins by providing a background on Deep Learning. This introduction serves to remind users to maintain an open mind - 
that underestimating the constraints and capabilities of deep learning can be problematic, and sometimes the solution is simpler or less-complex
than one might expect.\
Computer vision is highlighted as a major field in which deep learning can assist - namely, object recognition and detection (e.g. in radiology). Other uses of deep learning are noted as natural language processing, like Google's online translation system, combining words and images, like sending high priority alerts from CT scans, or tabular data, like recommendation systems on sites like Amazon.  
However, deep learning is faulted in that its models generally can't recognise or detect images or objects that are not used in its training 
data. This can be counteracted to some degree using *data augmentation*. A further limitation highlighted is the ability for the model to offer helpful, rather than just liked, recommendations to the user. 
### Drivetrain Approach
The course delves into the Drivetrain Approach, an approach used to develop a deep learning model that is practically useful. The model 
requires the following steps:
1. Defined objective - what are we trying to achieve?
2. Levers - what inputs can we control?
3. Data - what data can we collect?
4. Models - how do the levers influence the data?  
This approach encourages consideration of how the model can benefit the overall system, based on experimental data.
### Practical - Bear Classification
#### Data Loaders
The thin DataLoaders class is introduced here, which provide the data for the model, segmenting it into train and valid propertied. 
The DataBlocks API is also introduced as a flexible system, laying out the independent and dependent variables for predictions, 
and creating the DataLoader. 
#### Data Augmentation
Data augmentation is used to create a robust model by forming random variation of the data, namely through:
- Flipping
- Rotation
- Change in Brightness
- Change in Contrast
- Perspective Warping
#### Training and Output
The learning is performed practically, producing an output for classifying grizzly, black or teddy bears, as seen through the confusion matrix below. \
![image](https://github.com/bree-hoff/bree-hoff.github.io/assets/111101248/947e0348-81cb-40e9-8bd9-33fb5b0227a4) \
The error rates of ~0.158 and ~0.238 in the training are exhibited in the top losses seen below. \
![image](https://github.com/bree-hoff/bree-hoff.github.io/assets/111101248/7b349aec-f154-4ad3-82de-36da090af7cb) \

An application is recommended as a useful platform to improve user-friendliness in problems such as these. 

