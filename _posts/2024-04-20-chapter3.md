# Chapter 3: Ethics
### Recourse Processes, Feedback Loops, Bias
Bugs in software models, like that in the Healthcare Benefit algorithm example, dangerous feedback loops, like Youtube's conspiracy theory feedback loop and damaging bias, like that of Latanya Sweeney's racially-biased arrest ads, can have serious ethical consequences. It was interesting to consider that one may be involved in a large-scale data science project, which unbeknownst to them, might actually be supporting a problematic, negative regime. Equally, there is potential for this technology and its benefits to go towards positive change, for a data scientist to contribute to ground-breaking technology that may revolutionize fields like medicine.
Perhaps the most shocking imagery of this ethical drawback in code, was in the racial bias in matching images of congress-people to mugshots - the majority of which were people of colour (Seen below). \
![image](https://github.com/bree-hoff/bree-hoff.github.io/assets/111101248/c7bca442-aa7e-4dae-8eea-63681a1c180b)

### Solutions
This course highlights the requirement for audit and error correction mechanisms, as well as holding some degree of accountability over our own machine learning developments. As developers, it is important to break unhelpful or problematic feedback loops as soon as they are detected in our algorithm - to avoid, in extreme examples, pushing political agendas or shaping home videos into content for pedophiles.
Due to bias (i.e. measurement bias, agreggation bias and representation bias) in datasets being so pervasive, this should be counteracted via more diverse datasets, but largely should be mitigated by only specifying the scenario for the model for which it has been tested.


