# Chapter 19: Learner

## Chapter 18
I worked through Chapters 18 independently of the blog, and as such, I am picking up from Chapter 19: A Fastai Learner from Scratch.

## Building a fastai Learner From Scratch
The Learner is constructed by:
- Gathering Some Data: Collect data using fastdownload.
- Building a Model and Dataset: Uses ProcessPoolExecutor, Parameter() and Module()
- Creating a Loss Function: Uses Cross-Entropy loss:
  ```python
  loss = nll(sm, yb)
  loss
  ```
- Create the Learning Class:
  ```python
  class Learner:
    def __init__(self, model, dls, loss_func, lr, cbs, opt_func=SGD):
        store_attr()
        for cb in cbs: cb.learner = self

    def one_batch(self):
        self('before_batch')
        xb,yb = self.batch
        self.preds = self.model(xb)
        self.loss = self.loss_func(self.preds, yb)
        if self.model.training:
            self.loss.backward()
            self.opt.step()
        self('after_batch')

    def one_epoch(self, train):
        self.model.training = train
        self('before_epoch')
        dl = self.dls.train if train else self.dls.valid
        for self.num,self.batch in enumerate(progress_bar(dl, leave=False)):
            self.one_batch()
        self('after_epoch')
    
    def fit(self, n_epochs):
        self('before_fit')
        self.opt = self.opt_func(self.model.parameters(), self.lr)
        self.n_epochs = n_epochs
        try:
            for self.epoch in range(n_epochs):
                self.one_epoch(True)
                self.one_epoch(False)
        except CancelFitException: pass
        self('after_fit')
        
    def __call__(self,name):
        for cb in self.cbs: getattr(cb,name,noop)()
  ```
This Learning class is markedly large, but all that is notable here is that the learner's one_batch() function which processes a single batch of data during training, computes predictions, calculates losses and performs optimisation. The one_epoch() function works to set the model's training mode, calls the callback functions 'before_epoch' and 'after epoch' around the iteration over batches in the training/calidation DataLoader. Finally, the fit() function initialises the optimisers and learning rate.

Thanks for reading!
